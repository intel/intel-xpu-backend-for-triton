# Clones PyTorch (or loads from cache) to directory "pytorch".
# Uses the existing Python.
# Sets the following environment variables:
# * PYTORCH_REPO
# * PYTORCH_COMMIT_ID
# * PYTORCH_VERSION
name: setup-pytorch
description: Build and install PyTorch wheels
inputs:
  oneapi:
    description: Directory with oneAPI BaseKit
    default: /opt/intel/oneapi
  repository:
    description: Repository name with owner
    default: pytorch/pytorch
  ref:
    description: Branch, tag, commit id
    default: ""
  mode:
    description: Source or wheels
    default: source
  cache:
    description: Cache enabled or disabled
    default: enabled
runs:
  using: "composite"
  steps:
    - name: Set default commit id
      if: inputs.ref == ''
      shell: bash
      run: |
        PYTORCH_COMMIT_ID="$(<.github/pins/pytorch.txt)"
        echo "PYTORCH_REPO=${{ inputs.repository }}" | tee -a "$GITHUB_ENV"
        echo "PYTORCH_COMMIT_ID=$PYTORCH_COMMIT_ID" | tee -a "$GITHUB_ENV"

    - name: Identify commit id
      if: inputs.ref != ''
      id: commit-id
      uses: ./.github/actions/get-commit-id
      with:
        repository: ${{ inputs.repository }}
        branch: ${{ inputs.ref }}

    - name: Set commit id
      if: inputs.ref != ''
      shell: bash
      run: |
        if [[ "${{ inputs.repository }}" = "liangan1/pytorch" ]]; then
          PYTORCH_COMMIT_ID="$(<.github/pins/pytorchFlexAttention.txt)"
          echo "PYTORCH_REPO=${{ inputs.repository }}" | tee -a "$GITHUB_ENV"
          echo "PYTORCH_COMMIT_ID=$PYTORCH_COMMIT_ID" | tee -a "$GITHUB_ENV"
        else
          echo "PYTORCH_REPO=${{ inputs.repository }}" | tee -a "$GITHUB_ENV"
          echo "PYTORCH_COMMIT_ID=${{ steps.commit-id.outputs.commit_id }}" | tee -a "$GITHUB_ENV"
        fi

    - name: Identify Python version
      shell: bash
      run: |
        if [[ -z "$PYTHON_VERSION" ]]; then
          PYTHON_VERSION="$(python -c 'import sys; print(f"{sys.version_info[0]}.{ sys.version_info[1]}")')"
          echo "PYTHON_VERSION=$PYTHON_VERSION" >> "$GITHUB_ENV"
        fi

    # PyTorch build process expects Intel oneAPI in /opt/intel/oneapi
    - name: Set up oneAPI
      shell: bash
      run: |
        if [[ -d /opt/intel/oneapi ]]; then
          exit 0
        fi
        if [[ -L /opt/intel/oneapi ]]; then
          exit 0
        fi
        sudo mkdir -p /opt/intel
        sudo ln -sfT ${{ inputs.oneapi }} /opt/intel/oneapi

    - name: Generate PyTorch cache key
      shell: bash
      run: |
        ONEAPI_LINK=$(readlink /opt/intel/oneapi || true)
        ONEAPI_KEY=$(sha256sum /opt/intel/installed.txt 2> /dev/null | cut -d\  -f1 || true)
        PYTORCH_CACHE_KEY=$(echo $PYTHON_VERSION $PYTORCH_COMMIT_ID ${{ hashFiles('scripts/patch-pytorch.sh') }} ${{ inputs.mode }}${ONEAPI_KEY}${ONEAPI_LINK} | sha256sum - | cut -d\  -f1)
        echo "PYTORCH_CACHE_KEY=$PYTORCH_CACHE_KEY" | tee -a "$GITHUB_ENV"

    - name: Load PyTorch from a cache
      id: pytorch-cache
      uses: ./.github/actions/load
      env:
        # Increase this value to reset cache
        CACHE_NUMBER: 16
      with:
        path: pytorch
        key: pytorch-$PYTORCH_CACHE_KEY-$CACHE_NUMBER
        enabled: ${{ inputs.cache == 'enabled' }}

    - name: Clone PyTorch repository
      if: ${{ steps.pytorch-cache.outputs.status == 'miss' }}
      uses: actions/checkout@v4
      with:
        repository: ${{ env.PYTORCH_REPO }}
        ref: ${{ env.PYTORCH_COMMIT_ID }}
        # To build PyTorch from source we need all submodules, they are not required for benchmarks
        submodules: ${{ inputs.mode == 'source' && 'recursive' || 'false' }}
        path: pytorch

    - name: Apply additional PR patches
      if: ${{ steps.pytorch-cache.outputs.status == 'miss'  && inputs.mode == 'source' && (inputs.repository == 'pytorch/pytorch' || inputs.repository == 'liangan1/pytorch') }}
      shell: bash
      run: |
        cd pytorch
        ../scripts/patch-pytorch.sh

    - name: Build PyTorch
      if: ${{ steps.pytorch-cache.outputs.status == 'miss' && inputs.mode == 'source' }}
      shell: bash
      run: |
        source ${{ inputs.oneapi }}/setvars.sh

        # Limit AOT to PVC when compiling with LTS driver
        # See https://github.com/intel/intel-xpu-backend-for-triton/pull/3548#issuecomment-2685718019
        source ./scripts/capture-hw-details.sh
        if [[ $AGAMA_VERSION =~ 803 ]]; then
          export TORCH_XPU_ARCH_LIST="pvc"
        else
          export TORCH_XPU_ARCH_LIST="pvc,bmg,dg2,arl-h,mtl-h"
        fi

        cd pytorch
        pip install wheel
        pip install -r requirements.txt
        USE_XCCL=1 USE_STATIC_MKL=1 CFLAGS="-Wno-error=maybe-uninitialized" python setup.py bdist_wheel 2>&1 | grep -v \
          "Double arithmetic operation is not supported on this platform with FP64 conversion emulation mode (poison FP64 kernels is enabled)." | grep -v '^$'

    - name: Install PyTorch (built from source)
      if: ${{ inputs.mode == 'source' }}
      shell: bash
      run: |
        source ${{ inputs.oneapi }}/setvars.sh
        pip install pytorch/dist/*.whl

    - name: Install PyTorch (from wheels)
      if: ${{ inputs.mode == 'wheels' }}
      shell: bash
      run: |
        source ${{ inputs.oneapi }}/setvars.sh
        pip install torch --index-url https://download.pytorch.org/whl/nightly/xpu

    - name: Get PyTorch version
      shell: bash
      run: |
        source ${{ inputs.oneapi }}/setvars.sh
        PYTORCH_VERSION="$(python -c 'import torch;print(torch.__version__)')"
        echo "PYTORCH_VERSION=$PYTORCH_VERSION" | tee -a "$GITHUB_ENV"

    - name: Save PyTorch to a cache
      if: ${{ steps.pytorch-cache.outputs.status == 'miss' }}
      uses: ./.github/actions/save
      with:
        path: ${{ steps.pytorch-cache.outputs.path }}
        dest: ${{ steps.pytorch-cache.outputs.dest }}
        enabled: ${{ inputs.cache == 'enabled' }}
