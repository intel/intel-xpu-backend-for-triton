From caec8c3569aa6a7440d1bcf43dff10c2596036af Mon Sep 17 00:00:00 2001
From: Stonepia <tong.su@intel.com>
Date: Wed, 2 Aug 2023 14:34:40 +0000
Subject: [PATCH] Enabling inductor tests for xpu

---
 test/inductor/pytest.ini                   |   3 +
 test/inductor/test_minifier.py             |  49 ++-
 test/inductor/test_pattern_matcher.py      |  40 ++-
 test/inductor/test_perf.py                 |   6 +-
 test/inductor/test_smoke.py                |  16 +-
 test/inductor/test_torchinductor.py        | 399 ++++++++++++---------
 test/inductor/test_torchinductor_opinfo.py | 212 ++++++++++-
 torch/testing/_internal/inductor_utils.py  |  11 +-
 8 files changed, 515 insertions(+), 221 deletions(-)
 create mode 100644 test/inductor/pytest.ini

diff --git a/test/inductor/pytest.ini b/test/inductor/pytest.ini
new file mode 100644
index 0000000000..26056e15bd
--- /dev/null
+++ b/test/inductor/pytest.ini
@@ -0,0 +1,3 @@
+# Temporarily adds config files. So that we don't need adding more arguments
+[pytest]
+addopts = --ignore=opinfo_harness.py --ignore=test_config.py -k xpu
diff --git a/test/inductor/test_minifier.py b/test/inductor/test_minifier.py
index 2c3f8787f2..2ec9bea757 100644
--- a/test/inductor/test_minifier.py
+++ b/test/inductor/test_minifier.py
@@ -8,10 +8,17 @@ import torch._dynamo
 import torch._inductor.utils
 from torch._dynamo.test_minifier_common import MinifierTestBase
 from torch.testing._internal.common_utils import IS_MACOS
+from torch.testing._internal.inductor_utils import HAS_XPU

 _HAS_TRITON = torch._inductor.utils.has_triton()
 requires_cuda = functools.partial(unittest.skipIf, not _HAS_TRITON, "requires cuda")

+
+try:
+    from .test_torchinductor import requires_cuda_or_xpu, HAS_CUDA
+except ImportError:
+    from test_torchinductor import requires_cuda_or_xpu
+
 CPP_COMPILE_ERROR = """\
 def cpp_compile_error(x):
     return "compile error!"
@@ -43,6 +50,7 @@ def triton_accuracy_error(x):
     return f"{x} + 1"
 """

+acc_backend = "cuda" if HAS_CUDA else "xpu"

 class MinifierTests(MinifierTestBase):
     @classmethod
@@ -109,15 +117,15 @@ torch._dynamo.config.debug_dir_root = "{self.DEBUG_DIR}"
         self.assertIn("AccuracyError", tb1)
         self.assertIn("AccuracyError", tb2)

-    @requires_cuda()
-    def test_after_aot_cuda_compile_error(self):
-        (tb1, tb2), _ = self._test_after_aot("cuda", TRITON_COMPILE_ERROR, 2)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_compile_error(self):
+        (tb1, tb2), _ = self._test_after_aot(acc_backend, TRITON_COMPILE_ERROR, 2)
         self.assertIn("SyntaxError", tb1)
         self.assertIn("SyntaxError", tb2)

-    @requires_cuda()
-    def test_after_aot_cuda_accuracy_error(self):
-        (tb1, tb2), _ = self._test_after_aot("cuda", TRITON_ACCURACY_ERROR, 4)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_accuracy_error(self):
+        (tb1, tb2), _ = self._test_after_aot(acc_backend, TRITON_ACCURACY_ERROR, 4)
         self.assertIn("AccuracyError", tb1)
         self.assertIn("AccuracyError", tb2)

@@ -154,9 +162,9 @@ torch._dynamo.config.debug_dir_root = "{self.DEBUG_DIR}"

     # NOTE: there is currently not an easy way to cause a triton runtime error.
     @unittest.skip
-    @requires_cuda()
-    def test_after_aot_cuda_runtime_error(self):
-        self._test_after_aot_runtime_error("cuda", TRITON_RUNTIME_ERROR)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_runtime_error(self):
+        self._test_after_aot_runtime_error(acc_backend, TRITON_RUNTIME_ERROR)

     # Ensure that inductor codegen patches pass when relu is not present.
     def _test_after_aot_backend_passes(self, device, repro_level, backend_code):
@@ -190,19 +198,19 @@ torch._dynamo.config.debug_dir_root = "{self.DEBUG_DIR}"
     def test_after_aot_cpu_accuracy_backend_passes(self):
         self._test_after_aot_backend_passes("cpu", 4, CPP_ACCURACY_ERROR)

-    @requires_cuda()
-    def test_after_aot_cuda_compile_backend_passes(self):
-        self._test_after_aot_backend_passes("cuda", 2, TRITON_COMPILE_ERROR)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_compile_backend_passes(self):
+        self._test_after_aot_backend_passes(acc_backend, 2, TRITON_COMPILE_ERROR)

     # NOTE: there is currently not an easy way to cause a triton runtime error.
     @unittest.skip
-    @requires_cuda()
-    def test_after_aot_cuda_runtime_backend_passes(self):
-        self._test_after_aot_backend_passes("cuda", 2, TRITON_RUNTIME_ERROR)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_runtime_backend_passes(self):
+        self._test_after_aot_backend_passes(acc_backend, 2, TRITON_RUNTIME_ERROR)

-    @requires_cuda()
-    def test_after_aot_cuda_accuracy_backend_passes(self):
-        self._test_after_aot_backend_passes("cuda", 4, TRITON_ACCURACY_ERROR)
+    @requires_cuda_or_xpu()
+    def test_after_aot_cuda_or_xpu_accuracy_backend_passes(self):
+        self._test_after_aot_backend_passes(acc_backend, 4, TRITON_ACCURACY_ERROR)

     # Test that inductor config can be saved and restored, especially class
     # variables.
@@ -313,4 +321,7 @@ if __name__ == "__main__":

     # skip CI tests on mac since CPU inductor does not seem to work due to C++ compile errors
     if not IS_MACOS:
-        run_tests()
+        if HAS_XPU:
+            run_tests(needs="intel_extension_for_pytorch")
+        else:
+            run_tests()
diff --git a/test/inductor/test_pattern_matcher.py b/test/inductor/test_pattern_matcher.py
index 7bba18e6bf..786231d89e 100644
--- a/test/inductor/test_pattern_matcher.py
+++ b/test/inductor/test_pattern_matcher.py
@@ -3,19 +3,19 @@ import torch
 from torch._dynamo.test_case import run_tests, TestCase
 from torch._dynamo.utils import counters
 from torch.testing._internal.common_utils import IS_LINUX
-from torch.testing._internal.inductor_utils import HAS_CUDA
-
+from torch.testing._internal.inductor_utils import HAS_CUDA, HAS_XPU

+device_backend = "cuda" if HAS_CUDA else "xpu"
 class TestPaternMatcher(TestCase):
     def test_mm_plus_mm(self):
         def fn(a, b, c, d):
             return torch.add(torch.mm(a, b), torch.mm(c, d))

         args = [
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
         ]
         expected = fn(*args)
         actual = torch.compile(fn)(*args)
@@ -28,9 +28,9 @@ class TestPaternMatcher(TestCase):
             return torch.add(a, torch.mm(b, c)), torch.mm(a, b) + c

         args = [
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
         ]
         e1, e2 = fn(*args)
         a1, a2 = torch.compile(fn)(*args)
@@ -51,9 +51,9 @@ class TestPaternMatcher(TestCase):
             )

         args = [
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
         ]
         expected = fn(*args)
         actual = torch.compile(fn)(*args)
@@ -73,9 +73,9 @@ class TestPaternMatcher(TestCase):
             )

         args = [
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
-            torch.randn(16, 16, device="cuda"),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
+            torch.randn(16, 16, device=device_backend),
         ]
         expected = fn(*args)
         actual = torch.compile(fn)(*args)
@@ -91,8 +91,8 @@ class TestPaternMatcher(TestCase):
             return torch.ops.aten.cat.default([cat_1, slice_2], 1)

         args = [
-            torch.randn(2, 32, device="cuda"),
-            torch.randn(2, 16, device="cuda"),
+            torch.randn(2, 32, device=device_backend),
+            torch.randn(2, 16, device=device_backend),
         ]
         expected = fn(*args)
         actual = torch.compile(fn)(*args)
@@ -102,8 +102,8 @@ class TestPaternMatcher(TestCase):

         counters.clear()
         args = [
-            torch.randn(2, 8, device="cuda"),
-            torch.randn(2, 16, device="cuda"),
+            torch.randn(2, 8, device=device_backend),
+            torch.randn(2, 16, device=device_backend),
         ]
         expected = fn(*args)
         actual = torch.compile(fn)(*args)
@@ -115,3 +115,5 @@ class TestPaternMatcher(TestCase):
 if __name__ == "__main__":
     if IS_LINUX and HAS_CUDA:
         run_tests()
+    if IS_LINUX and HAS_XPU:
+        run_tests(needs="intel_extension_for_pytorch")
diff --git a/test/inductor/test_perf.py b/test/inductor/test_perf.py
index 9279e4a9d8..d1a4b1aac4 100644
--- a/test/inductor/test_perf.py
+++ b/test/inductor/test_perf.py
@@ -15,7 +15,7 @@ from torch.testing._internal.common_utils import (
     TEST_WITH_ROCM,
     TestCase as TorchTestCase,
 )
-from torch.testing._internal.inductor_utils import HAS_CUDA
+from torch.testing._internal.inductor_utils import HAS_CUDA, HAS_XPU

 aten = torch.ops.aten

@@ -64,7 +64,7 @@ def count_numel_train(f, *args):
     return str(metrics.num_bytes_accessed // 4)


-DEVICE = "cuda"
+DEVICE = "cuda" if HAS_CUDA else "xpu"


 def T(*size, dtype=torch.float32, device=DEVICE, grad=False):
@@ -520,3 +520,5 @@ if __name__ == "__main__":

     if HAS_CUDA and not TEST_WITH_ROCM:
         run_tests(needs="filelock")
+    if HAS_XPU and not TEST_WITH_ROCM:
+        run_tests(needs=("filelock", "intel_extension_for_pytorch"))
diff --git a/test/inductor/test_smoke.py b/test/inductor/test_smoke.py
index 9f23e12e5e..12af5c745c 100644
--- a/test/inductor/test_smoke.py
+++ b/test/inductor/test_smoke.py
@@ -1,10 +1,12 @@
 # Owner(s): ["module: inductor"]
 import logging
+import unittest

 import torch
 import torch._dynamo as torchdynamo
 import torch._inductor.config as torchinductor_config
 from torch.testing._internal.common_utils import IS_LINUX, TestCase
+from torch.testing._internal.inductor_utils import HAS_CUDA, HAS_XPU


 class MLP(torch.nn.Module):
@@ -24,19 +26,23 @@ def _test_f(x):


 class SmokeTest(TestCase):
+    @unittest.skipIf(not HAS_CUDA and not HAS_XPU, "Triton is not available")
     def test_mlp(self):
+        device_backend = "cuda" if HAS_CUDA else "xpu"
         torchdynamo.config.log_level = logging.INFO
         torchdynamo.config.verbose = True
         torchinductor_config.debug = True

-        mlp = torch.compile(MLP().cuda())
+        mlp = torch.compile(MLP().cuda()) if HAS_CUDA else torch.compile(MLP().xpu())
         for _ in range(3):
-            mlp(torch.randn(1, device="cuda"))
+            mlp(torch.randn(1, device=device_backend))

         torchdynamo.config.verbose = False
         torchinductor_config.debug = False

+    @unittest.skipIf(not HAS_CUDA and not HAS_XPU, "Triton is not available")
     def test_compile_decorator(self):
+        device_backend = "cuda" if HAS_CUDA else "xpu"
         @torch.compile
         def foo(x):
             return torch.sin(x) + x.min()
@@ -46,8 +52,8 @@ class SmokeTest(TestCase):
             return x * x

         for _ in range(3):
-            foo(torch.full((3, 4), 0.7, device="cuda"))
-            bar(torch.rand((2, 2), device="cuda"))
+            foo(torch.full((3, 4), 0.7, device=device_backend))
+            bar(torch.rand((2, 2), device=device_backend))

     def test_compile_invalid_options(self):
         with self.assertRaises(RuntimeError):
@@ -60,3 +66,5 @@ if __name__ == "__main__":
     if IS_LINUX and torch.cuda.is_available():
         if torch.cuda.get_device_properties(0).major > 5:
             run_tests()
+    if IS_LINUX and HAS_XPU:
+        run_tests(needs="intel_extension_for_pytorch")
diff --git a/test/inductor/test_torchinductor.py b/test/inductor/test_torchinductor.py
index f0c152adbc..5e0843bc00 100644
--- a/test/inductor/test_torchinductor.py
+++ b/test/inductor/test_torchinductor.py
@@ -82,15 +82,26 @@ from torch._inductor.sizevars import SizeVarAllocator
 from torch._inductor.utils import has_torchvision_roi_align, timed
 from torch.fx.experimental.symbolic_shapes import FloorDiv

-from torch.testing._internal.inductor_utils import HAS_CPU, HAS_CUDA
+from torch.testing._internal.inductor_utils import HAS_CPU, HAS_CUDA, HAS_XPU

 HAS_MULTIGPU = HAS_CUDA and torch.cuda.device_count() >= 2
+HAS_MULTIXPU = HAS_XPU and torch.xpu.device_count() >= 2
+
 HAS_AVX2 = "fbgemm" in torch.backends.quantized.supported_engines
 aten = torch.ops.aten
 requires_cuda = functools.partial(unittest.skipIf, not HAS_CUDA, "requires cuda")
+requires_xpu = functools.partial(unittest.skipIf, not HAS_XPU, "requires xpu")
+
+requires_cuda_or_xpu = functools.partial(unittest.skipIf, (not HAS_CUDA) and (not HAS_XPU), "requires cuda or xpu")
 requires_multigpu = functools.partial(
     unittest.skipIf, not HAS_MULTIGPU, "requires multiple cuda devices"
 )
+requires_multixpu = functools.partial(
+    unittest.skipIf, not HAS_MULTIXPU, "requires multiple xpu devices"
+)
+requires_multi_gpu_or_xpu = functools.partial(
+    unittest.skipIf, not HAS_MULTIXPU or not HAS_MULTIGPU, "requires multiple xpu devices"
+)
 slow = functools.partial(unittest.skipIf, not TEST_WITH_SLOW, "too slow")
 skip_if_x86_mac = functools.partial(
     unittest.skipIf, IS_MACOS and IS_X86, "Does not work on x86 Mac"
@@ -257,6 +268,8 @@ class InputGen:
         return torch.randn((1,), device=self.device)

     def double(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         return torch.randn((self.n, self.n), device=self.device, dtype=torch.double)

     def int(self):
@@ -531,6 +544,80 @@ def check_model_cuda(
             check_gradient=check_gradient,
         )

+@torch._inductor.config.patch("triton.cudagraphs", False)
+def check_model_xpu(
+    self: TestCase,
+    model,
+    example_inputs,
+    kwargs=None,
+    *,
+    atol=None,
+    rtol=None,
+    check_lowp=True,
+    exact_dtype=True,
+    nopython=True,
+    copy_to_xpu=True,
+    reference_in_float=True,
+    assert_equal=True,
+    check_gradient=False,
+):
+    kwargs = kwargs or {}
+    if hasattr(model, "to"):
+        model = model.to("xpu")
+
+    def copy_fn(x):
+        # preserve strides of the input on the device
+        if not isinstance(x, torch.Tensor):
+            return x
+        return torch.empty_strided(
+            x.size(), x.stride(), device="xpu", dtype=x.dtype
+        ).copy_(x)
+
+    if copy_to_xpu:
+        example_inputs = tuple(copy_fn(x) for x in example_inputs)
+
+    check_model(
+        self,
+        model,
+        example_inputs,
+        kwargs,
+        atol=atol,
+        rtol=rtol,
+        exact_dtype=exact_dtype,
+        nopython=nopython,
+        reference_in_float=reference_in_float,
+        assert_equal=assert_equal,
+        check_gradient=check_gradient,
+    )
+
+    if check_lowp:
+
+        def downcast_fn(x):
+            if not isinstance(x, torch.Tensor) or not x.dtype == torch.float:
+                return x
+            return torch.empty_strided(
+                x.size(), x.stride(), device="xpu", dtype=torch.half
+            ).copy_(x)
+
+        example_inputs = list(map(downcast_fn, example_inputs))
+        if hasattr(model, "to"):
+            model = model.to(torch.half)
+        if rtol is not None:
+            rtol = max(2e-3, rtol)
+        check_model(
+            self,
+            model,
+            example_inputs,
+            kwargs,
+            atol=atol,
+            rtol=rtol,
+            exact_dtype=exact_dtype,
+            nopython=nopython,
+            reference_in_float=reference_in_float,
+            assert_equal=assert_equal,
+            check_gradient=check_gradient,
+        )
+

 class SweepInputs2:
     input_gen_types1 = [
@@ -893,7 +980,7 @@ class CommonTemplate:
         self.assertEqual(torch._inductor.metrics.ir_nodes_pre_fusion, 5)
         self.assertEqual(
             torch._inductor.metrics.generated_kernel_count,
-            1 if self.device == "cuda" else 3,
+            1 if self.device == "xpu" or self.device == "cuda" else 3,
         )

     def test_sum1(self):
@@ -1014,7 +1101,7 @@ class CommonTemplate:
     def test_multilayer_low_prec(self):
         # fp16 nyi for cpu
         if self.device == "cpu":
-            raise unittest.SkipTest("requires CUDA")
+            raise unittest.SkipTest("requires CUDA or XPU")

         def fn(a):
             return torch.mean(a)
@@ -1049,6 +1136,8 @@ class CommonTemplate:
             self.common(fn, (i,), check_lowp=False)

     def test_sum_dtype(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(x):
             return x * x.sum(-1, dtype=torch.double) + x.sum(dtype=torch.double)

@@ -1061,6 +1150,8 @@ class CommonTemplate:
         self.common(fn, (torch.randn(8, 8), torch.randn(8, 8)))

     def test_clamp_type_promotion(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(a):
             b = torch.tensor(1.0, dtype=torch.double, device=self.device)
             c = torch.full((4,), 2, device=self.device)
@@ -1270,6 +1361,8 @@ class CommonTemplate:
         self.common(fn, (torch.randn(8, 8) * 100, torch.randn(8, 8) * 10))

     def test_round_correctness(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         if self.device == "cuda":
             raise unittest.SkipTest("need to debug tl.libdevice on A100/V100")

@@ -1679,7 +1772,7 @@ class CommonTemplate:
     @slow()
     def test_conv_bn_fuse(self):
         # For gpu path, there is an accuracy issue
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == 'xpu':
             raise unittest.SkipTest("only support cpu conv bn test")

         input_shapes = {1: (112,), 2: (112, 112), 3: (55, 55, 55)}
@@ -1720,7 +1813,7 @@ class CommonTemplate:
             ).eval()
             test_memory_format = [torch.contiguous_format]
             # TODO: GPU path doesn't support channels_last now.
-            if not HAS_CUDA and dim > 1:
+            if (not HAS_XPU or not HAS_CUDA) and dim > 1:
                 channels_last = (
                     torch.channels_last if dim == 2 else torch.channels_last_3d
                 )
@@ -1737,7 +1830,7 @@ class CommonTemplate:

     def test_conv_functional_bn_fuse(self):
         # For gpu path, there is an accuracy issue
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv bn test")

         # Define a BatchNorm using functional BN.
@@ -1820,7 +1913,7 @@ class CommonTemplate:
             )

     def test_upsample_cat_conv(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu upsample_cat_conv test")

         class M(torch.nn.Module):
@@ -1856,7 +1949,7 @@ class CommonTemplate:
             )

     def test_conv2d_packed(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv2d packed test")

         x_shape = (1, 3, 56, 56)
@@ -1875,7 +1968,7 @@ class CommonTemplate:
     def test_conv2d_unary(self):
         # For gpu path, there is an accuracy issue
         # see https://github.com/pytorch/pytorch/issues/87745
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv2d unary test")

         class M(torch.nn.Module):
@@ -1951,7 +2044,7 @@ class CommonTemplate:
     def test_conv2d_binary(self):
         # For gpu path, there is an accuracy issue
         # see https://github.com/pytorch/pytorch/issues/87745
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv2d binary test")

         class M(torch.nn.Module):
@@ -2155,7 +2248,7 @@ class CommonTemplate:
                     self.common(mod, (v, other), atol=2e-3, rtol=0.016)

     def test_conv_transpose2d_packed(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv_transpose2d packed test")

         x_shape = (1, 3, 28, 28)
@@ -2168,7 +2261,7 @@ class CommonTemplate:
             )

     def test_conv_transpose2d_unary(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv_transpose2d unary test")

         class M(torch.nn.Module):
@@ -2318,6 +2411,8 @@ class CommonTemplate:
         )

     def test_to_dtype(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(a, b):
             return (
                 aten._to_copy(a, dtype=6),
@@ -2334,11 +2429,11 @@ class CommonTemplate:
             ),
         )

-    @requires_cuda()
+    @requires_xpu()
     def test_to_device(self):
         def fn(a):
             if a.device.type == "cpu":
-                return aten._to_copy(a, device=torch.device("cuda"), dtype=6, layout=0)
+                return aten._to_copy(a, device=torch.device("xpu"), dtype=6, layout=0)
             else:
                 return aten._to_copy(a, device=torch.device("cpu"), dtype=6, layout=0)

@@ -2363,12 +2458,12 @@ class CommonTemplate:
             ),
         )

-    @requires_cuda()
+    @requires_xpu()
     def test_to_device_constant(self):
         def fn(a):
             d1 = a.device.type
             if d1 == "cpu":
-                d2 = "cuda"
+                d2 = "xpu"
             else:
                 d2 = "cpu"

@@ -2384,18 +2479,18 @@ class CommonTemplate:
             (torch.randn([10]),),
         )

-    @requires_cuda()
+    @requires_multixpu()
     def test_multi_device(self):
         def fn(x):
             x = x + 1
             x = x + 2
-            x = x.cuda()
+            x = x.xpu()
             x = x + 3
             x = x + 4
             x = x.cpu()
             x = x + 5
             x = x + 6
-            x = x.cuda()
+            x = x.xpu()
             x = x + 7
             x = x + 8
             x = x.cpu()
@@ -2409,16 +2504,16 @@ class CommonTemplate:
             check_lowp=False,  # cpu doesn't understand fp16, and there are explicit .cpu() calls
         )

-    @requires_multigpu()
+    @requires_multixpu()
     def test_multi_gpu_device(self):
         def fn(x, y):
             r = torch.ops.aten.div(x, y)
-            r = r.to("cuda:1")
+            r = r.to("xpu:1")
             return 2 * r

         self.common(fn, (torch.randn(4), torch.randn(4)), check_lowp=False)

-    @requires_multigpu()
+    @requires_multi_gpu_or_xpu()
     def test_recompile_on_index(self):
         torch.set_float32_matmul_precision("high")

@@ -2490,7 +2585,7 @@ class CommonTemplate:
         )

     def test_conv2d_channels_last(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv2d channels_last")

         m = torch.nn.Sequential(
@@ -2545,7 +2640,7 @@ class CommonTemplate:
         )

     def test_conv3d_channels_last(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("only support cpu conv3d channels_last")

         m = torch.nn.Sequential(
@@ -3083,7 +3178,7 @@ class CommonTemplate:
         for inp in (
             torch.randn(
                 [16, 16],
-                dtype=torch.float16 if self.device == "cuda" else torch.float32,
+                dtype=torch.float16 if (self.device == "cuda" or self.device == "xpu") else torch.float32,
                 device=self.device,
             ),
             torch.randint(16, (16, 16), device=self.device),
@@ -3125,6 +3220,8 @@ class CommonTemplate:
         )

     def test_pow2(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(x):
             return aten.pow(1000, x), aten.pow(x, 1000)

@@ -3165,6 +3262,8 @@ class CommonTemplate:
         )

     def test_cat(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(a):
             tmp = a * 2
             return (
@@ -3312,6 +3411,8 @@ class CommonTemplate:
             return torch.expm1(x), torch.expm1(x) * 2

         for dtype in (torch.float16, torch.float, torch.double, torch.int, torch.int64):
+            if (not torch.xpu.utils.has_fp64_dtype()) and dtype in (torch.double):
+                continue
             self.common(
                 fn,
                 (torch.randn([64]).to(dtype=dtype),),
@@ -3326,6 +3427,8 @@ class CommonTemplate:
             return torch.log1p(x), torch.log1p(x) * 2

         for dtype in (torch.float16, torch.float, torch.double, torch.int, torch.int64):
+            if (not torch.xpu.utils.has_fp64_dtype()) and dtype in (torch.double):
+                continue
             self.common(
                 fn,
                 (torch.randn([64]).to(dtype=dtype),),
@@ -3398,6 +3501,8 @@ class CommonTemplate:
         )

     def test_log_fp64(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(x):
             return torch.log(x), torch.log2(x)

@@ -3594,8 +3699,8 @@ class CommonTemplate:
             )

     def test_cudnn_rnn(self):
-        if self.device == "cpu":
-            raise unittest.SkipTest("requires CUDA")
+        if self.device == "cpu" or self.device == "xpu":
+            raise unittest.SkipTest("requires cuda")

         def fn(
             a0,
@@ -3890,6 +3995,8 @@ class CommonTemplate:

     def test_constant_pad_float64(self):
         # Repro for https://github.com/pytorch/pytorch/issues/93351
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         def fn(input):
             v1 = torch.nn.functional.pad(input, pad=(1, 0))
             return torch.gt(v1, input)
@@ -3922,6 +4029,7 @@ class CommonTemplate:

         self.common(fn, (torch.randn([8, 1, 1]),))

+    @requires_cuda_or_xpu()
     def test_inplace_add(self):
         @torch._dynamo.optimize("inductor")
         def fn(x, y):
@@ -3938,7 +4046,7 @@ class CommonTemplate:

     # The following 2 tests are meant to check the logic that drops
     # xmask from triton load/store if xnumel = 1
-    @requires_cuda()
+    @requires_cuda_or_xpu()
     def test_single_elem(self):
         def fn(a):
             b = a + 1
@@ -3946,7 +4054,7 @@ class CommonTemplate:

         self.common(fn, (torch.randn(1),))

-    @requires_cuda()
+    @requires_cuda_or_xpu()
     def test_single_elem_indirect(self):
         def fn(a, b):
             c = a[b] + 1
@@ -3958,6 +4066,8 @@ class CommonTemplate:
         self.common(fn, (a, b))

     def test_inplace_mixed_dtype_ops(self):
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         @torch._dynamo.optimize("inductor")
         def fn(x, y):
             z = x + y.float()
@@ -3983,7 +4093,8 @@ class CommonTemplate:
         inputs = (rand_strided((8,), (1,), device=self.device),)
         self.assertTrue(same(fn(*inputs), 2 * inputs[0]))

-    @config.patch({"triton.cudagraphs": True})
+    @requires_xpu()
+    @config.patch({"triton.cudagraphs": False})
     def test_strided_inputs(self):
         @torch._dynamo.optimize("inductor")
         def fn(x, y):
@@ -3995,7 +4106,8 @@ class CommonTemplate:
         )
         self.assertTrue(same(fn(*inputs), inputs[0] + inputs[1]))

-    @config.patch({"triton.cudagraphs": True})
+    @requires_xpu()
+    @config.patch({"triton.cudagraphs": False})
     @patch.object(functorch_config, "use_fake_tensor", True)
     def test_input_mutation1(self):
         def fn(a):
@@ -4167,6 +4279,8 @@ class CommonTemplate:
         self.common(
             fn, [torch.tensor([1, float("inf"), 2, float("-inf"), float("nan")])]
         )
+        if (not torch.xpu.utils.has_fp64_dtype()):
+            raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
         self.common(
             fn,
             [
@@ -4505,7 +4619,7 @@ class CommonTemplate:
         )

     def test_scatter2(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("unstable on sm86")

         def fn(a, dim, index, b):
@@ -4521,6 +4635,7 @@ class CommonTemplate:
             ],
         )

+    @unittest.skip("error: undefined reference to `__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16'")
     def test_scatter3(self):
         def fn(a, dim, index, b):
             return aten.scatter(a, dim, index, b, reduce="add")
@@ -4564,6 +4679,7 @@ class CommonTemplate:
             ],
         )

+    @unittest.skip("error: undefined reference to `__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16'")
     def test_scatter_add2(self):
         def fn(a, dim, index, b):
             return aten.scatter_add(a, dim, index, b)
@@ -4578,6 +4694,7 @@ class CommonTemplate:
             ],
         )

+    @unittest.skip("error: undefined reference to `__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16'")
     def test_scatter_add3(self):
         def fn(a, dim, index, b):
             return aten.scatter_add(a, dim, index, b)
@@ -4664,7 +4781,7 @@ class CommonTemplate:

         self.common(fn, [torch.randn(55)], assert_equal=False)

-    @config.patch({"triton.cudagraphs": True})
+    @config.patch({"triton.cudagraphs": False if HAS_XPU else True})
     def test_dropout(self):
         random.seed(1234)
         torch.manual_seed(1234)
@@ -4689,6 +4806,7 @@ class CommonTemplate:
         self.assertTrue(400 < result2.nonzero().shape[0] < 600)
         self.assertTrue(0.9 < result2.mean().item() < 1.1)

+    @requires_cuda()
     def test_dropout_deterministic(self):
         @torch._dynamo.optimize("inductor")
         def fn(a):
@@ -4878,6 +4996,7 @@ class CommonTemplate:
         )
         self.assertEqual(torch._inductor.metrics.generated_kernel_count, 1)

+    @unittest.skip("oneDNN only supports pooling backward with fp32 and bf16 datatype")
     def test_max_pool2d_with_indices_backward5(self):
         # Window size is too big. Should fallback
         def fn(a, b, c):
@@ -4994,6 +5113,7 @@ class CommonTemplate:
         )
         self.assertEqual(torch._inductor.metrics.generated_kernel_count, 0)

+    @config.patch(search_autotune_cache=False)
     def test_mm_views(self):
         def fn(a, b):
             return torch.mm(a.view(32, 32), b.view(32, 32))
@@ -5066,6 +5186,7 @@ class CommonTemplate:
         self.assertTrue(same(r2, r3))
         self.assertTrue(same(g2, g3))

+    @config.patch(search_autotune_cache=False)
     def test_lowmem_dropout2(self):
         m = torch.nn.Sequential(
             torch.nn.Linear(32, 32, bias=False),
@@ -5428,8 +5549,10 @@ class CommonTemplate:
         ]

         for d in dtypes:
+            if (not torch.xpu.utils.has_fp64_dtype()) and d in [torch.float64, torch.double]:
+                continue
             inputs = (
-                rand_strided((2, 3), (3, 1), dtype=torch.float32, device="cuda"),
+                rand_strided((2, 3), (3, 1), dtype=torch.float32, device="xpu"),
                 rand_strided((), (), dtype=d, device="cpu"),
             )
             self.assertTrue(same(opt(*inputs), fn(*inputs)))
@@ -5437,8 +5560,7 @@ class CommonTemplate:
             self.assertTrue(same(opt(*inputs), fn(*inputs)))

     def test_list_clearing(self):
-
-        if self.device == "cpu":
+        if self.device == "cpu" or self.device == "xpu":
             contexts = [contextlib.nullcontext]
         else:
             contexts = [
@@ -5503,7 +5625,7 @@ class CommonTemplate:
         self.assertEqual(res, res_ref)

     def test_kwargs(self):
-        if self.device == "cuda":
+        if self.device == "cuda" or self.device == "xpu":
             raise unittest.SkipTest("histogramdd only supports cpu")

         def fn(x, y):
@@ -5518,7 +5640,7 @@ class CommonTemplate:
             [torch.randn((4, 2)), torch.randn((4))],
         )

-    @unittest.skipIf(HAS_CUDA, "test in_out_ptr for CppKernel")
+    @unittest.skipIf(HAS_CUDA or HAS_XPU, "test in_out_ptr for CppKernel (expected)")
     def test_in_out_buffer(self):
         def fn(x, y):
             z = torch.matmul(x, y.transpose(-1, -2)) / 8.0
@@ -5546,9 +5668,9 @@ class CommonTemplate:
             e.name for e in prof.profiler.function_events
         )

-    @config.patch(cpp_wrapper=True)
+    @config.patch(cpp_wrapper=True, search_autotune_cache=False)
     def test_cpp_wrapper(self):
-        if self.device == "cuda":
+        if self.device == "xpu" or self.device == 'cuda':
             raise unittest.SkipTest("cpp_wrapper only supports cpu")

         device = "cpu"
@@ -6550,25 +6672,25 @@ if HAS_CPU:
             assert metrics.generated_cpp_vec_kernel_count == 0


-if HAS_CUDA and not TEST_WITH_ASAN:
+if HAS_XPU and not TEST_WITH_ASAN:
     import triton
     import triton.language as tl

-    class SweepInputsCudaTest(SweepInputs2, TestCase):
-        gen = InputGen(10, "cuda")
+    class SweepInputsXpuTest(SweepInputs2, TestCase):
+        gen = InputGen(10, "xpu")

-    SweepInputsCudaTest.populate()
+    SweepInputsXpuTest.populate()

-    class CudaTests(TestCase):
-        common = check_model_cuda
-        device = "cuda"
+    class XpuTests(TestCase):
+        common = check_model_xpu
+        device = "xpu"

         def test_simplify_dims(self):
             def fn(a):
                 return (a + 1,)

             self.common(
-                fn, (torch.randn(2, 3, 10, 5, 6, device="cuda")[:, :, 2::2, :, :],)
+                fn, (torch.randn(2, 3, 10, 5, 6, device="xpu")[:, :, 2::2, :, :],)
             )

         def test_sink_cat_after_pointwise(self):
@@ -6580,8 +6702,8 @@ if HAS_CUDA and not TEST_WITH_ASAN:

             trace_func = chain_passes(torch.fx.symbolic_trace, sink_cat_after_pointwise)
             inputs = [
-                torch.randn(8, 8, device="cuda"),
-                torch.randn(8, 8, device="cuda"),
+                torch.randn(8, 8, device="xpu"),
+                torch.randn(8, 8, device="xpu"),
             ]
             for f in [test_kwarg, test_arg]:
                 traced = trace_func(f, inputs)
@@ -6623,8 +6745,8 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                     return (bmm,)

             args = [
-                ((1024, 642, 160), (102720, 160, 1), torch.float32, "cuda", True),
-                ((1024, 642, 20), (12840, 20, 1), torch.float32, "cuda", True),
+                ((1024, 642, 160), (102720, 160, 1), torch.float32, "xpu", True),
+                ((1024, 642, 20), (12840, 20, 1), torch.float32, "xpu", True),
             ]
             args = [
                 rand_strided(sh, st, dt, dev).requires_grad_(rg)
@@ -6644,10 +6766,10 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 aten.add_.Tensor(x, y, alpha=0.55)
                 return (x,)

-            x1 = torch.zeros(2, 3, 4, 10, device="cuda")
-            x2 = torch.zeros(2, 3, 4, 10, device="cuda")
-            x3 = torch.zeros(2, 3, 4, 10, device="cuda")
-            y = torch.randn(2, 3, 4, 10, device="cuda").to(
+            x1 = torch.zeros(2, 3, 4, 10, device="xpu")
+            x2 = torch.zeros(2, 3, 4, 10, device="xpu")
+            x3 = torch.zeros(2, 3, 4, 10, device="xpu")
+            y = torch.randn(2, 3, 4, 10, device="xpu").to(
                 memory_format=torch.channels_last
             )
             fn_fx = make_fx(fn)(x1, y)
@@ -6662,9 +6784,9 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 a = x @ y
                 return a.unsqueeze(0).unsqueeze(0) + z

-            x = torch.zeros(5, 5, device="cuda")
-            y = torch.zeros(5, 5, device="cuda")
-            z = torch.zeros(1, 1, 5, 5, device="cuda").to(
+            x = torch.zeros(5, 5, device="xpu")
+            y = torch.zeros(5, 5, device="xpu")
+            z = torch.zeros(1, 1, 5, 5, device="xpu").to(
                 memory_format=torch.channels_last
             )
             self.common(
@@ -6722,11 +6844,11 @@ if HAS_CUDA and not TEST_WITH_ASAN:

             self.assertTrue(torch.allclose(module(input), traced(input)))

-    copy_tests(CommonTemplate, CudaTests, "cuda")
-    copy_tests(DynamicShapesCommonTemplate, CudaTests, "cuda")
+    copy_tests(CommonTemplate, XpuTests, "xpu")
+    copy_tests(DynamicShapesCommonTemplate, XpuTests, "xpu")

-    class CudaReproTests(TestCase):
-        common = check_model_cuda
+    class XpuReproTests(TestCase):
+        common = check_model_xpu

         def test_index_put_issue(self):
             def forward(
@@ -6758,20 +6880,20 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 (torch.Size([512, 768]), torch.float16),
             ]
             inps = [torch.zeros(())] + [
-                torch.ones(shape, dtype=dtype, device="cuda") for (shape, dtype) in inps
+                torch.ones(shape, dtype=dtype, device="xpu") for (shape, dtype) in inps
             ]
             mod = make_fx(forward)(*inps)
             compiled = compile_fx_inner(mod, inps)
             compiled(inps)

-        @requires_cuda()
+        @requires_xpu()
         def test_input_channels_last(self):
             m = torch.nn.Sequential(
                 torch.nn.Conv2d(3, 3, 1, 1),
                 ToTuple(),
-            ).cuda()
+            ).xpu()
             inp = (
-                torch.randn([2, 3, 16, 16]).to(memory_format=torch.channels_last).cuda()
+                torch.randn([2, 3, 16, 16]).to(memory_format=torch.channels_last).xpu()
             )

             self.common(
@@ -6789,7 +6911,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             )

         # https://github.com/pytorch/torchdynamo/issues/1681#issuecomment-1283433527
-        @requires_cuda()
+        @requires_xpu()
         def test_unspec_inputs_interop(self):
             class Repro(torch.nn.Module):
                 def forward(self, x, y):
@@ -6800,20 +6922,20 @@ if HAS_CUDA and not TEST_WITH_ASAN:

             inps = [
                 rand_strided(
-                    (12, 3, 512, 64), (64, 196608, 768, 1), torch.float32, "cuda"
+                    (12, 3, 512, 64), (64, 196608, 768, 1), torch.float32, "xpu"
                 ),
                 rand_strided((), (), torch.int64, "cpu"),
             ]
-            mod = make_fx(Repro().to(device="cuda"))(*inps)
+            mod = make_fx(Repro().to(device="xpu"))(*inps)
             compiled = compile_fx_inner(mod, inps)
             compiled(inps)

-        @requires_cuda()
+        @requires_xpu()
         def test_backward_context(self):
             def fn(x):
                 return x * 3

-            x = torch.randn(4, device="cuda", requires_grad=True)
+            x = torch.randn(4, device="xpu", requires_grad=True)
             gO = torch.rand_like(x)
             opt_fn = torch.compile(fn)
             out = opt_fn(x)
@@ -6825,7 +6947,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 randn = torch.ops.aten.randn.default(
                     [12, 64, 1, 64],
                     dtype=torch.float32,
-                    device=torch.device(type="cuda", index=0),
+                    device=torch.device(type="xpu", index=0),
                     pin_memory=False,
                 )
                 unsqueeze_default_2 = torch.ops.aten.unsqueeze.default(randn, -1)
@@ -6833,19 +6955,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:

             mod = make_fx(forward)()
             compiled = compile_fx_inner(mod, ())
-            assert compiled([])[0].device.type == "cuda"
-
-        @config.patch({"triton.cudagraphs": True})
-        def test_expanded_inputs_cudagraphs(self):
-            @torch._dynamo.optimize("inductor")
-            def fn(x, y):
-                return x + y
-
-            inputs = (
-                rand_strided((5, 5, 5, 5), (0, 5, 0, 1), device="cuda"),
-                rand_strided((5, 5, 5, 5), (0, 5, 0, 1), device="cuda"),
-            )
-            self.assertTrue(same(fn(*inputs), inputs[0] + inputs[1]))
+            assert compiled([])[0].device.type == "xpu"

         # TODO: Abstract this out, test more extensively
         @torch._dynamo.config.patch(dynamic_shapes=True)
@@ -6869,18 +6979,6 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             self.assertEqual(real_out, compiled_out)
             torch._dynamo.reset()

-        @config.patch({"triton.cudagraphs": True, "size_asserts": False})
-        def test_expanded_inputs_cudagraphs_no_size_asserts(self):
-            @torch._dynamo.optimize("inductor")
-            def fn(x, y):
-                return x + y
-
-            inputs = (
-                rand_strided((5, 5, 5, 5), (0, 5, 0, 1), device="cuda"),
-                rand_strided((5, 5, 5, 5), (0, 5, 0, 1), device="cuda"),
-            )
-            self.assertTrue(same(fn(*inputs), inputs[0] + inputs[1]))
-
         @config.patch(tune_layout=True)
         def test_tune_layout(self):
             class Repro(torch.nn.Module):
@@ -6900,9 +6998,9 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                     return (convolution_1,)

             args = [
-                ((512,), (1,), torch.float16, "cuda"),
-                ((4096, 512, 16, 1), (8192, 16, 1, 1), torch.float16, "cuda"),
-                ((512, 512, 3, 1), (1536, 3, 1, 1), torch.float16, "cuda"),
+                ((512,), (1,), torch.float16, "xpu"),
+                ((4096, 512, 16, 1), (8192, 16, 1, 1), torch.float16, "xpu"),
+                ((512, 512, 3, 1), (1536, 3, 1, 1), torch.float16, "xpu"),
             ]
             args = [rand_strided(sh, st, dt, dev) for (sh, st, dt, dev) in args]

@@ -6912,42 +7010,6 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             res = opt_mod(*args)
             self.assertTrue(same(ref, res))

-        @config.patch({"triton.cudagraphs": True})
-        def test_inplace_updates_cudagraphs(self):
-            class Repro(torch.nn.Module):
-                def __init__(self):
-                    super().__init__()
-                    self.weight1 = torch.nn.Parameter(
-                        torch.randn(10, 20, requires_grad=True)
-                    )
-
-                def forward(self, x):
-                    x = torch.matmul(x, self.weight1)
-                    return x
-
-            from copy import deepcopy
-
-            model = Repro().cuda()
-            model_ref = deepcopy(model)
-            model_opt = torch._dynamo.optimize("inductor")(model)
-
-            input = torch.randn(10, 10, device="cuda", requires_grad=True)
-
-            for i in range(2):
-                output_ref = model_ref(input)
-                output_res = model_opt(input)
-                output_ref.sum().backward()
-                output_res.sum().backward()
-                for (p_ref, p_res) in zip(
-                    model_ref.parameters(), model_opt.parameters()
-                ):
-                    self.assertEqual(p_ref.grad, p_res.grad)
-                with torch.no_grad():
-                    for param in model_ref.parameters():
-                        param.add_(1.0)
-                    for param in model_opt.parameters():
-                        param.add_(1.0)
-
         # https://github.com/pytorch/torchdynamo/issues/1850
         def test_inductor_output_aliases_intermediate(self):
             def foo(x):
@@ -6956,7 +7018,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:

             foo_opt = torch._dynamo.optimize("inductor")(foo)

-            inpt = torch.randn(10, 10, device="cuda", requires_grad=True)
+            inpt = torch.randn(10, 10, device="xpu", requires_grad=True)
             # TODO: this is broken, fix later
             # out = foo_opt(inpt)
             # out.add_(2)
@@ -6984,20 +7046,20 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                     )
                     return cross_entropy

-            mod = Repro().cuda()
+            mod = Repro().xpu()
             opt_mod = torch._dynamo.optimize("inductor")(mod)
             mod.eval()
             opt_mod.eval()

             args = [
-                ((1,), (1,), torch.int64, "cuda", False),
-                ((1, 128, 768), (98304, 768, 1), torch.float32, "cuda", True),
+                ((1,), (1,), torch.int64, "xpu", False),
+                ((1, 128, 768), (98304, 768, 1), torch.float32, "xpu", True),
             ]
             args = [
                 rand_strided(sh, st, dt, dev).requires_grad_(rg)
                 for (sh, st, dt, dev, rg) in args
             ]
-            with torch.cuda.amp.autocast(enabled=False):
+            with torch.xpu.amp.autocast(enabled=False):
                 assert same_two_models(mod, opt_mod, args), "Dynamo failed"

         def test_autotune_inplace_kernel(self):
@@ -7007,7 +7069,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             https://github.com/openai/triton/issues/781
             https://github.com/pytorch/torchdynamo/issues/1670
             """
-            from torch._C import _cuda_getCurrentRawStream as get_cuda_stream
+            from intel_extension_for_pytorch._C import _getCurrentRawStream as get_xpu_stream
             from torch._inductor.triton_ops.autotune import CachingAutotuner, grid
             from torch._inductor.utils import instance_descriptor

@@ -7050,11 +7112,11 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 tl.store(in_out_ptr0 + offsets, output, mask=mask)

             xnumel = 384
-            in0 = rand_strided((xnumel,), (1,), device="cuda", dtype=torch.float32)
-            inout1 = rand_strided((xnumel,), (1,), device="cuda", dtype=torch.float32)
+            in0 = rand_strided((xnumel,), (1,), device="xpu", dtype=torch.float32)
+            inout1 = rand_strided((xnumel,), (1,), device="xpu", dtype=torch.float32)
             inout2 = inout1.clone()

-            stream0 = get_cuda_stream(0)
+            stream0 = get_xpu_stream(0)
             kernel.run(inout1, in0, xnumel, grid=grid(xnumel), stream=stream0)
             kernel.run(inout2, in0, xnumel, grid=grid(xnumel), stream=stream0)

@@ -7062,7 +7124,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 inout1, inout2, tol=0.001, equal_nan=True
             ), "failed autotune with inplace kernel"

-        @requires_cuda()
+        @requires_xpu()
         def test_sort_stride_issue(self):
             # This minified testcase comes from detectron2_maskrcnn_r_50_fpn
             # There was a false error from our size_assert code
@@ -7072,7 +7134,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 getitem_12 = sort_3[0]
                 return getitem_12

-            args = [((1, 100), (0, 1), torch.float16, "cuda", False)]
+            args = [((1, 100), (0, 1), torch.float16, "xpu", False)]
             args = [
                 rand_strided(sh, st, dt, dev).requires_grad_(rg)
                 for (sh, st, dt, dev, rg) in args
@@ -7080,7 +7142,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             result = forward(*args)
             assert same(result, torch.sort(args[0], descending=True, dim=1)[0])

-        @requires_cuda()
+        @requires_xpu()
         def test_scalar_triton_index(self):
             # The indirect indexing via a scalar like below used to lead to
             # bad triton code that made triton segfault when compiling.
@@ -7089,12 +7151,12 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 zero = torch.zeros((16,), device=a.device, dtype=torch.int64)
                 return (a[zero],)

-            a = torch.randn((8,), dtype=torch.float32, device="cuda")
+            a = torch.randn((8,), dtype=torch.float32, device="xpu")

             fn_optimized = torch._dynamo.optimize("inductor")(fn)
             assert same(fn(a), fn_optimized(a))

-        @requires_cuda()
+        @requires_xpu()
         def test_indirect_indexing_dense_mask(self):
             def fn(x, y):
                 ne = torch.ops.aten.ne.Scalar(x, 1)
@@ -7106,8 +7168,8 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 out = torch.ops.aten.multiply(y, squeeze)
                 return (out,)

-            a = torch.zeros((1, 128), dtype=torch.int64, device="cuda")
-            b = torch.zeros((1, 128), dtype=torch.int64, device="cuda")
+            a = torch.zeros((1, 128), dtype=torch.int64, device="xpu")
+            b = torch.zeros((1, 128), dtype=torch.int64, device="xpu")

             fn_optimized = torch._dynamo.optimize("inductor")(fn)
             assert same(fn(a, b), fn_optimized(a, b))
@@ -7177,7 +7239,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             def fn(a: torch.Tensor) -> torch.Tensor:
                 return torch.sum(a)

-            kernels = self.get_kernels(fn, [torch.randn([256, 256], device="cuda")])
+            kernels = self.get_kernels(fn, [torch.randn([256, 256], device="xpu")])
             self.assertTrue(len(kernels) == 2, "SUM should result in two kernels")

             # kernel0 reduces from 256 to (xnumel=8, rnumel=8192), which means it reduces 256 by 256 into an array of
@@ -7200,7 +7262,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 return aten.upsample_bilinear2d.vec(x, None, True, [2.0, 2.0])

             fn_opt = torch._dynamo.optimize("inductor")(fn)
-            inps = [torch.randn(2, 4, 16, 16).cuda()]
+            inps = [torch.randn(2, 4, 16, 16).xpu()]
             code = run_and_get_triton_code(fn_opt, *inps)
             self.assertTrue("to(tl.int32)" in code)
             self.assertFalse("to(tl.int64)" in code)
@@ -7215,8 +7277,8 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             K = 7
             fn_opt = torch._dynamo.optimize("inductor")(fn)
             inps = [
-                torch.randn(N, 1, K, device="cuda"),
-                torch.randn(1, N, K, device="cuda"),
+                torch.randn(N, 1, K, device="xpu"),
+                torch.randn(1, N, K, device="xpu"),
             ]
             code = run_and_get_triton_code(fn_opt, *inps)
             self.assertEqual(code.count("tl.store"), 1)
@@ -7225,13 +7287,15 @@ if HAS_CUDA and not TEST_WITH_ASAN:
             self.assertEqual(fn_opt(*inps), fn(*inps))

         def test_cant_optimize_compute(self):
+            if (not torch.xpu.utils.has_fp64_dtype()):
+                raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
             def ones():
-                return torch.ones([4], device="cuda")
+                return torch.ones([4], device="xpu")

             def suffix(inp):
                 return (inp.to(torch.int64) + 1).to(torch.float64)

-            ten = torch.rand([4], device="cuda")
+            ten = torch.rand([4], device="xpu")

             for foo in (
                 lambda x: x + 2147483657,
@@ -7251,8 +7315,10 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 self.assertEqual(fn_opt(), fn())

         def test_optimize_compute(self):
+            if (not torch.xpu.utils.has_fp64_dtype()):
+                raise unittest.SkipTest("Platform Does not support FP64, but encountered a FP64 value")
             def ones():
-                return torch.ones([4], device="cuda")
+                return torch.ones([4], device="xpu")

             def suffix(inp):
                 return (inp.to(torch.int64) + 1).to(torch.float64)
@@ -7319,8 +7385,8 @@ class ExprPrinterTests(TestCase):
         self.assertEqual(pexpr(expr), "math.floor(s1)")


-if HAS_CUDA and not TEST_WITH_ASAN:
-
+if (HAS_XPU or HAS_CUDA) and not TEST_WITH_ASAN:
+    device_backend = "cuda" if HAS_CUDA else "xpu"
     class RNNTest(TestCase):
         class Model(torch.nn.Module):
             def __init__(self):
@@ -7331,7 +7397,7 @@ if HAS_CUDA and not TEST_WITH_ASAN:
                 return self.gru(x)

         def test_rnn_compile_safe(self):
-            device = torch.device("cuda")
+            device = torch.device(device_backend)
             model = RNNTest.Model().to(device)
             model = torch._dynamo.optimize("inductor")(model)
             x = torch.rand(1024, 20, 16).to(device)
@@ -7341,5 +7407,8 @@ if HAS_CUDA and not TEST_WITH_ASAN:
 if __name__ == "__main__":
     from torch._dynamo.test_case import run_tests

-    if (HAS_CPU or HAS_CUDA) and not TEST_WITH_ROCM:
-        run_tests(needs="filelock")
+    if (HAS_CPU or HAS_CUDA or HAS_XPU) and not TEST_WITH_ROCM:
+        if HAS_XPU:
+            run_tests(needs=("filelock", "intel_extension_for_pytorch"))
+        else:
+            run_tests(needs="filelock")
diff --git a/test/inductor/test_torchinductor_opinfo.py b/test/inductor/test_torchinductor_opinfo.py
index d91a27684b..827e69d0f1 100644
--- a/test/inductor/test_torchinductor_opinfo.py
+++ b/test/inductor/test_torchinductor_opinfo.py
@@ -31,13 +31,13 @@ from torch.testing._internal.common_utils import (
     suppress_warnings,
     TestCase,
 )
-from torch.testing._internal.inductor_utils import HAS_CPU, HAS_CUDA
+from torch.testing._internal.inductor_utils import HAS_CPU, HAS_CUDA, HAS_XPU

 try:
     try:
-        from .test_torchinductor import check_model, check_model_cuda
+        from .test_torchinductor import check_model, check_model_cuda, check_model_xpu
     except ImportError:
-        from test_torchinductor import check_model, check_model_cuda
+        from test_torchinductor import check_model, check_model_cuda, check_model_xpu
 except (unittest.SkipTest, ImportError) as e:
     sys.stderr.write(f"{type(e)}: {e}\n")
     if __name__ == "__main__":
@@ -58,8 +58,17 @@ c32 = torch.complex32
 c64 = torch.complex64
 c128 = torch.complex128

+allowed_dtypes=[f16, f32, i32, i64, b8]
+
+if HAS_XPU:
+    allowed_dtypes += [bf16]
+
+if torch.xpu.utils.has_fp64_dtype():
+    allowed_dtypes += [f64]
+
+
 _ops = partial(
-    ops, dtypes=OpDTypes.supported, allowed_dtypes=[f16, f32, f64, i32, i64, b8]
+    ops, dtypes=OpDTypes.supported, allowed_dtypes=allowed_dtypes
 )

 # Success forces pass; failure forces fail; skip unconditionally skips testing
@@ -117,6 +126,7 @@ inductor_expected_failures_single_sample[\"{device_type}\"] = {{
         )

     process("cpu")
+    process("xpu")
     process("cuda")


@@ -130,6 +140,22 @@ inductor_skips["cpu"] = {
     "linalg.ldl_factor": {f32, f64},  # flaky
     "__rdiv__": {b8, f16, f32, f64, i32, i64},  # flaky
     "nn.functional.cosine_embedding_loss": {b8},  # flaky
+}
+
+if IS_MACOS and IS_X86:
+    inductor_skips["cpu"]["rsqrt"] = {b8, i32}
+
+inductor_skips["xpu"] = {
+    # Jiterator kernel is not expected to work with inductor
+    "jiterator_2inputs_2outputs": {b8, f16, f32, f64, i32, i64},
+    "jiterator_4inputs_with_extra_args": {b8, f16, f32, f64, i32, i64},
+    "jiterator_binary": {b8, f16, f32, f64, i32, i64},
+    "jiterator_binary_return_by_ref": {b8, f16, f32, f64, i32, i64},
+    "jiterator_unary": {b8, f16, f32, f64, i32, i64},
+    # flaky
+    "nn.functional.cosine_embedding_loss": {b8},
+    "native_batch_norm": {f16, f32, f64},
+    "_native_batch_norm_legit": {f16, f32, f64},
     # fft ops sometimes succeed locally and fail on CI.
     # they return complex values which is known unsupported,
     # so there is not much point in testing them currently.
@@ -151,10 +177,14 @@ inductor_skips["cpu"] = {
     "fft.rfft": {f16, f32, f64, b8, i32, i64},
     "fft.rfft2": {f16, f32, f64},
     "fft.rfftn": {f16, f32, f64},
+    # Ops that only run on cpu, but not on xpu.
+    # CUDA skips it in `OpInfo`, but xpu is as an addition module
+    # Thus, skip it here.
+    "histogram":  {b8, f16, f32, f64, i32, i64},
+    "histogramadd":  {b8, f16, f32, f64, i32, i64},
+
 }

-if IS_MACOS and IS_X86:
-    inductor_skips["cpu"]["rsqrt"] = {b8, i32}

 inductor_skips["cuda"] = {
     # Jiterator kernel is not expected to work with inductor
@@ -272,6 +302,84 @@ inductor_expected_failures_single_sample["cpu"] = {
 }


+
+inductor_expected_failures_single_sample["xpu"] = {
+    "__getitem__": {b8, f16, f32, f64, i32, i64},
+    "__rdiv__": {b8, f16, f32, f64, i32, i64},
+    "allclose": {f16, f32, f64},
+    "angle": {f32, f64},
+    "argwhere": {b8, f16, f32, f64, i32, i64},
+    "baddbmm": {f16},
+    "bernoulli": {f16, f32, f64},
+    "bincount": {i32, i64},
+    "bucketize": {b8, f16, f32, f64, i32, i64},
+    "cdouble": {b8, i32, i64, f16, f32, f64, c32, c64, c128},
+    "cfloat": {b8, i32, i64, f16, f32, f64, c32, c64, c128},
+    "chalf": {b8, i32, i64, f16, f32, f64, c32, c64, c128},
+    "cholesky": {f32, f64},
+    "combinations": {b8, f16, f32, f64, i32, i64},
+    "complex": {f16, f32, f64},
+    "corrcoef": {f16, f32, f64, i32, i64},
+    "cov": {f16, f32, f64, i32, i64},
+    "equal": {b8, f16, f32, f64, i32, i64},
+    "index_reduce": {f16, f32, f64},
+    "istft": {f32, f64},
+    "linalg.eig": {f32, f64},
+    "linalg.eigh": {f32, f64},
+    "linalg.eigvals": {f32, f64},
+    "linalg.eigvalsh": {f32, f64},
+    "linalg.lstsq": {f32, f64},
+    "linalg.lstsq.grad_oriented": {f32, f64},
+    "masked_scatter": {f16, f32, f64},
+    "masked_select": {b8, f16, f32, f64, i32, i64},
+    "max.reduction_with_dim": {b8},
+    "min.reduction_with_dim": {b8},
+    "multinomial": {f16, f32, f64},
+    "nn.functional.adaptive_avg_pool2d": {f16},
+    "nn.functional.ctc_loss": {f32, f64},
+    "nn.functional.grid_sample": {f16},
+    "grid_sampler_2d": {f16},
+    "nn.functional.gaussian_nll_loss": {f16, f32, f64},
+    "nn.functional.one_hot": {i64},
+    "nn.functional.rrelu": {f16, f32, f64},
+    "nn.functional.triplet_margin_with_distance_loss": {f16, f32, f64, i32, i64},
+    "nonzero": {b8, f16, f32, f64, i32, i64},
+    "normal": {f16, f32, f64},
+    "normal.number_mean": {f16, f32, f64},
+    "polar": {f32, f64},
+    "pow": {i32, i64},
+    "rand_like": {f16, f32, f64},
+    "randint_like": {f16, f32, f64, i32, i64},
+    "randint": {f16, f32, f64, i32, i64},
+    "randn_like": {f16, f32, f64},
+    "repeat_interleave": {b8, f16, f32, f64, i32, i64},
+    "round.decimals_3": {f16},
+    "scatter_reduce.prod": {f16, f32, f64},
+    "_segment_reduce.lengths": {f16, f32, f64},
+    "sparse.sampled_addmm": {f32, f64},
+    "stft": {f32, f64},
+    "tensor_split": {b8, f16, f32, f64, i32, i64},
+    "to_sparse": {f16, f32, f64},
+    # AssertionError: Tensor-likes are not close!
+    "cauchy": {f16, f32, f64},
+    "exponential": {f16, f32, f64},
+    "geometric": {f16, f32, f64, i32, i64},
+    "log_normal": {f16, f32, f64},
+    "uniform": {f16, f32, f64},
+    "unique": {b8, f16, f32, f64, i32, i64},
+    "unique_consecutive": {b8, f16, f32, f64, i32, i64},
+    # AssertionError: Tensor-likes are not close!
+    "nn.functional.triplet_margin_loss": {f16},
+    # The following 3 tests fail on CUDA with AssertionError: expected size 5==5, stride 5==1 at dim=0
+    # linalg._svd's return value has different strides on CUDA vs CPU which causes this
+    # In test_meta.py there is a mechanism to skipping strides checks for some ops
+    # (including _linalg_svd), possibly we should have something similar here
+    # AssertionError: Scalars are not close!
+    "nn.functional.soft_margin_loss": {f16},
+    # torch._dynamo.exc.BackendCompilerFailed: compile_fx_wrapper raised SyntaxError
+    "angle": {f16}
+}
+
 inductor_expected_failures_single_sample["cuda"] = {
     "__getitem__": {b8, f16, f32, f64, i32, i64},
     "__rdiv__": {b8, f16, f32, f64, i32, i64},
@@ -374,6 +482,26 @@ inductor_gradient_expected_failures_single_sample["cuda"] = {
     "tanh": {f16},
 }

+
+inductor_gradient_expected_failures_single_sample["xpu"] = {
+    "asin": {f16},
+    "cumprod": {f16},
+    "linalg.vector_norm": {f64, f64},
+    "kron": {f16},
+    "nanquantile": {f32, f64},
+    "nn.functional.avg_pool2d": {f16, f32, f64},
+    "nn.functional.batch_norm.without_cudnn": {f16},
+    "nn.functional.batch_norm": {f16},
+    "nn.functional.cosine_similarity": {f16},
+    "nn.functional.instance_norm": {f16},
+    "nn.functional.normalize": {f16},
+    "nn.functional.softsign": {f16},
+    "nn.functional.local_response_norm": {f16},
+    "outer": {f16},
+    "quantile": {f32, f64},
+    "tanh": {f16},
+}
+
 inductor_should_fail_with_exception = defaultdict(dict)

 inductor_should_fail_with_exception["cpu"] = {}
@@ -386,6 +514,12 @@ inductor_should_fail_with_exception["cuda"] = {
     }
 }

+inductor_should_fail_with_exception["xpu"] = {
+    "__rpow__": {
+        i32: "Pow input must be floating point.",
+        i64: "Pow input must be floating point.",
+    }
+}

 def wrapper_set_seed(op, *args, **kwargs):
     """Wrapper to set seed manually for some functions like dropout
@@ -406,18 +540,26 @@ torch._dynamo.variables.torch.tensor_dunder_fns.append(
 inductor_override_kwargs = {
     # the return value of empty is undefined
     "empty": {"assert_equal": False},
+    "empty_permuted": {"assert_equal": False},
     "empty_like": {"assert_equal": False},
     "new_empty": {"assert_equal": False},
     "new_empty_strided": {"assert_equal": False},
     "randn": {"assert_equal": False},
     ("masked.softmin", "cuda", f16): {"atol": 1e-4, "rtol": 0.01},
+    ("masked.softmin", "xpu", f16): {"atol": 1e-4, "rtol": 0.01},
     ("nn.functional.tanhshrink", "cuda", f16): {"atol": 3e-4, "rtol": 0.001},
+    ("nn.functional.tanhshrink", "xpu", f16): {"atol": 3e-4, "rtol": 0.001},
     ("nn.functional.softmin", "cuda", f16): {"atol": 1e-4, "rtol": 0.01},
+    ("nn.functional.softmin", "xpu", f16): {"atol": 1e-4, "rtol": 0.01},
     ("special.log_ndtr", "cuda", f64): {"atol": 1e-6, "rtol": 1e-5},
+    ("special.log_ndtr", "xpu", f64): {"atol": 1e-6, "rtol": 1e-5},
     ("cummax", "cuda", f16): {"atol": 5e-4, "rtol": 0.002},
+    ("cummax", "xpu", f16): {"atol": 5e-4, "rtol": 0.002},
     ("softmax", "cuda", f16): {"atol": 1e-4, "rtol": 0.02},
+    ("softmax", "xpu", f16): {"atol": 1e-4, "rtol": 0.02},
     ("softmax", "cpu", f16): {"atol": 1e-4, "rtol": 0.02},
     ("_softmax_backward_data", "cuda", f16): {"atol": 0.008, "rtol": 0.002},
+    ("_softmax_backward_data", "xpu", f16): {"atol": 0.008, "rtol": 0.002},
     "gradient": {"check_gradient": False},  # segfault on check_gradient
     # Following tests failed, and causing subsequent tests failing with unrecoverable CUDA error
     "linalg.solve_triangular": {"check_gradient": False},
@@ -451,12 +593,39 @@ inductor_all_samples = {
     "triu",
 }

+xpu_temp_skip_list = {
+
+    "nn.functional.linear": {
+        i64: "Long is not supported in oneDNN!",
+    },
+    "lgamma" : {
+        f64: "spirv link error: Unresolved external reference to __devicelib_imf_lgamma",
+    },
+    "index_add" : {
+        f16: "error: undefined reference to `__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16' in function: '__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16' called by kernel: 'triton__0d1d2d3'",
+    },
+    "index_select" : {
+        f16: "error: undefined reference to `__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16' in function: '__builtin_spirv_OpAtomicFAddEXT_p1f16_i32_i32_f16' called by kernel: 'triton__0d1d2d3'",
+    },
+    ("mvlgamma.mvlgamma_p_1"): {
+        f64: "spirv link error: Unresolved external reference to __devicelib_imf_lgamma",
+    },
+    ("mvlgamma.mvlgamma_p_3"): {
+        f64: "spirv link error: Unresolved external reference to __devicelib_imf_lgamma",
+    },
+    ("mvlgamma.mvlgamma_p_5"): {
+        f64: "spirv link error: Unresolved external reference to __devicelib_imf_lgamma",
+    },
+}

 class TestInductorOpInfo(TestCase):
     check_model = check_model
     check_model_cuda = check_model_cuda
+    check_model_xpu = check_model_xpu

-    @onlyNativeDeviceTypes
+    # TODO : SKIP XPU using SkipXPUIf
+    @unittest.skipIf(not HAS_XPU, "Skipped! Supported XPU not found")
+    # @onlyNativeDeviceTypes
     @suppress_warnings
     @skipCUDAMemoryLeakCheckIf(
         True
@@ -480,8 +649,11 @@ class TestInductorOpInfo(TestCase):

         device_type = torch.device(device).type

-        assert device_type in ("cuda", "cpu")
-
+        assert device_type in ("cuda", "cpu", "xpu")
+        if op_name in xpu_temp_skip_list:
+            dtype_reason_dict = xpu_temp_skip_list[op_name]
+            if dtype in dtype_reason_dict:
+                self.skipTest(dtype_reason_dict[dtype])
         # with open("test_output.txt", "a") as f:
         #     print(f"CONSIDERING OP {op_name} on {device_type} with {dtype} |
         # {inductor_skips[device_type].get(op_name, set())}", flush=True, file=f)
@@ -559,6 +731,23 @@ class TestInductorOpInfo(TestCase):
                         kwargs,
                         **adjusted_kwargs,
                     )
+                elif device_type == "xpu":
+                    # opinfo test case have already place the input on the correct device
+                    # so we don't need do additional copy by setting copy_to_cuda=False
+                    adjusted_kwargs = {
+                        "check_lowp": False,
+                        "nopython": True,
+                        "copy_to_xpu": False,
+                        "reference_in_float": False,
+                        "check_gradient": requires_grad,
+                    }
+                    adjusted_kwargs.update(overridden_kwargs)
+                    self.check_model_xpu(
+                        fn,
+                        args,
+                        kwargs,
+                        **adjusted_kwargs,
+                    )
                 elif device_type == "cpu":
                     adjusted_kwargs = {
                         "check_lowp": False,
@@ -611,4 +800,7 @@ class TestInductorOpInfo(TestCase):
 instantiate_device_type_tests(TestInductorOpInfo, globals())

 if __name__ == "__main__":
-    run_tests()
+    if HAS_XPU:
+        run_tests(needs=("intel_extension_for_pytorch"))
+    else:
+        run_tests()
diff --git a/torch/testing/_internal/inductor_utils.py b/torch/testing/_internal/inductor_utils.py
index 84750a2de3..5599c56bfe 100644
--- a/torch/testing/_internal/inductor_utils.py
+++ b/torch/testing/_internal/inductor_utils.py
@@ -1,7 +1,7 @@
 from subprocess import CalledProcessError

 from torch._inductor.codecache import CppCodeCache
-from torch._inductor.utils import has_triton
+from torch._inductor.utils import has_triton as has_cuda_triton
 from torch.testing._internal.common_utils import (
     IS_FBCODE,
     TEST_WITH_ROCM,
@@ -20,4 +20,11 @@ except (
 ):
     pass

-HAS_CUDA = has_triton() and not TEST_WITH_ROCM
+HAS_XPU = False
+try:
+    import intel_extension_for_pytorch as ipex
+    HAS_XPU = ipex._inductor.xpu.utils.has_triton()
+except ImportError:
+    pass
+
+HAS_CUDA = has_cuda_triton() and not TEST_WITH_ROCM
--
2.34.1
