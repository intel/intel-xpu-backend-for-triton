name: Build and test

on:
  workflow_dispatch:
  pull_request:
    branches:
      - llvm-target
  push:
    branches:
      - llvm-target

permissions: read-all

env:
  BASE: /home/runner
  LLVM_SYSPATH: /home/runner/packages/llvm
  BACKEND: XPU
  TRITON_DISABLE_LINE_INFO: 1

jobs:
  pre-commit:
    name: Pre-commit checks
    runs-on:
      - glados
      - spr
      - cpu
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Load pip cache
        id: pip-cache
        uses: ./.github/actions/load
        env:
          # Increase this value to reset cache
          CACHE_NUMBER: 1
        with:
          path: $HOME/.cache/pip
          key: pip-3.9-${{ hashFiles('.pre-commit-config.yaml') }}-${{ env.CACHE_NUMBER }}

      - name: Install Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Run pre-commit checks
        run: |
          pip install --upgrade pre-commit

          # TODO: ignore the first yapf failure until https://github.com/google/yapf/issues/1164 is fixed
          python3 -m pre_commit run --all-files --verbose yapf &> /dev/null || true
          # If first run of yapf worked and made changes reset the tree to the original state
          git reset --hard

          python3 -m pre_commit run --show-diff-on-failure --color=always --all-files --verbose

      - name: Save pip cache
        if: ${{ steps.pip-cache.outputs.status == 'miss' }}
        uses: ./.github/actions/save
        with:
          path: ${{ steps.pip-cache.outputs.path }}
          dest: ${{ steps.pip-cache.outputs.dest }}

  integration-tests:
    name: Integration tests
    runs-on:
      - glados
      - spr
      - runner-0.0.6
    strategy:
      matrix:
        python:
          - "3.9"
          - "3.10"
    defaults:
      run:
        shell: bash -noprofile --norc -eo pipefail -c "source /home/runner/intel/oneapi/setvars.sh > /dev/null; source {0}"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Load pip cache
        id: pip-cache
        uses: ./.github/actions/load
        env:
          # Increase this value to reset cache
          CACHE_NUMBER: 1
        with:
          path: $HOME/.cache/pip
          key: pip-${{ matrix.python }}-${{ hashFiles('python/pyproject.toml', 'python/setup.py') }}-${{ env.CACHE_NUMBER }}

      - name: Install Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Get LLVM commit id
        uses: ./.github/actions/get-commit-id
        with:
          repository: intel/llvm.git
          branch: genx
          variable: LLVM_COMMIT_ID

      - name: Calculate packages cache key
        run: |
          PACKAGES_CACHE_KEY=$(echo $LLVM_COMMIT_ID ${{ hashFiles('scripts/compile-triton.sh') }} | sha256sum - | cut -d\  -f1)
          echo "PACKAGES_CACHE_KEY=$PACKAGES_CACHE_KEY" >> "${GITHUB_ENV}"

      - name: Load packages cache
        id: packages-cache
        uses: ./.github/actions/load
        env:
          # Increase this value to reset cache
          CACHE_NUMBER: 1
        with:
          path: $HOME/packages
          key: packages-${{ env.PACKAGES_CACHE_KEY }}-${{ env.CACHE_NUMBER }}

      - name: Build packages
        if: ${{ steps.packages-cache.outputs.status == 'miss' }}
        run: |
          ./scripts/compile-triton.sh --llvm

      - name: Save packages cache
        if: ${{ steps.packages-cache.outputs.status == 'miss' }}
        uses: ./.github/actions/save
        with:
          path: ${{ steps.packages-cache.outputs.path }}
          dest: ${{ steps.packages-cache.outputs.dest }}

      - name: Setup PyTorch
        uses: ./.github/actions/setup-pytorch

      - name: Setup IPEX
        uses: ./.github/actions/setup-ipex

      - name: Build Triton
        run: |
          cd python
          pip install wheel pytest pytest-xdist pytest-rerunfailures
          pip install --no-build-isolation '.[build,tests,tutorials]'

      - name: Run lit tests
        run: |
          cd python
          lit -v build/*/test

      - name: Create directory for tests reports
        run: |
          mkdir ~/reports

      - name: Run core tests
        run: |
          cd python/test/unit
          python3 -m pytest --junitxml=~/reports/language.xml -n 8 --verbose --device xpu language/ --ignore=language/test_line_info.py
          # run runtime tests serially to avoid race condition with cache handling.
          python3 -m pytest --junitxml=~/reports/runtime.xml --device xpu runtime/
          # run test_line_info.py separately with TRITON_DISABLE_LINE_INFO=0
          TRITON_DISABLE_LINE_INFO=0 python3 -m pytest --junitxml=~/reports/line_info.xml --verbose --device xpu language/test_line_info.py

      - name: Clear cache
        run: |
          rm -rf ~/.triton

      - name: Run interpreter tests
        env:
          TRITON_INTERPRET: "1"
        run: |
          cd python/test/unit
          python3 -m pytest --junitxml=~/reports/interpreter_core.xml -vvv -n 4 -m interpreter language/test_core.py --device cpu

      # TODO: merge the two interpreter tests with env TRITON_INTERPRET=1 and device cpu
      - name: Run interpreter tests (test_flash_attention.py)
        # env:
          # TRITON_INTERPRET: "1"
        run: |
          cd python/test/unit
          python3 -m pytest --junitxml=~/reports/flash_attention.xml -n 8 -m interpreter -vvv -s operators/test_flash_attention.py::test_op --device xpu

      - name: Run partial operators tests
        run: |
          cd python/test/unit
          python3 -m pytest --junitxml=~/reports/operators.xml -n 8 --verbose --device xpu operators

      - name: Regression tests
        run: |
          cd python/test/regression
          python3 -m pytest --junitxml=~/reports/regression.xml -vvv -s --device xpu . --reruns 10 --ignore=test_performance.py

      - name: Run XPU python tests
        run: |
          cd python/test/backend/third_party_backends
          python3 -m pytest -n auto --verbose test_xpu_backend.py

      - name: Run Tutorials
        run: |
          cd python/tutorials
          python3 01-vector-add.py
          python3 02-fused-softmax.py
          python3 03-matrix-multiplication.py
          python3 04-low-memory-dropout.py
          python3 05-layer-norm.py
          python3 06-fused-attention.py
          python3 07-extern-functions.py
          python3 08-experimental-block-pointer.py
          python3 09-experimental-tma-matrix-multiplication.py
          python3 10-experimental-tma-store-matrix-multiplication.py
          python3 11-grouped-gemm.py

      - name: Run CXX unittests
        run: |
          cd python/build/*cmake*
          ctest

      - name: Run E2E test
        run: |
          # Set WORKSPACE for inductor_xpu_test.sh to make sure it creates "inductor_log" outside of pytorch cloned directory
          export WORKSPACE=$GITHUB_WORKSPACE
          cd pytorch
          TRANSFORMERS_VERSION="$(<.ci/docker/ci_commit_pins/huggingface.txt)"
          pip install pyyaml pandas scipy numpy psutil pyre_extensions torchrec transformers==$TRANSFORMERS_VERSION
          # TODO: Find the fastest Hugging Face model
          $GITHUB_WORKSPACE/scripts/inductor_xpu_test.sh huggingface float32 inference accuracy xpu 0 static 1 0 AlbertForMaskedLM
          # The script above always returns 0, so we need an additional check to see if the accuracy test passed
          cat $WORKSPACE/inductor_log/*/*/*.csv
          grep AlbertForMaskedLM $WORKSPACE/inductor_log/*/*/*.csv | grep -q ,pass,

      - name: Save pip cache
        if: ${{ steps.pip-cache.outputs.status == 'miss' }}
        uses: ./.github/actions/save
        with:
          path: ${{ steps.pip-cache.outputs.path }}
          dest: ${{ steps.pip-cache.outputs.dest }}

      - name: Pass rate
        run: |
          python3 scripts/pass_rate.py --reports ~/reports
          mkdir -p /cache/reports/pass-rate
          TMPFILE=$(mktemp -p /cache/reports/pass-rate XXXXXXXXXX)
          python3 scripts/pass_rate.py --reports ~/reports --json > $TMPFILE
          mv $TMPFILE $TMPFILE.json
