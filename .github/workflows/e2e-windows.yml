name: E2E on Windows
run-name: ${{ inputs.run_name }}

on:
  workflow_dispatch:
    inputs:
      suite:
        description: Test suite
        type: choice
        options:
          - all
          - huggingface
          - timm_models
          - torchbench
        default: all
      mode:
        description: Inference, inference-no-freezing, or training
        type: choice
        options:
          - all
          - inference
          - inference-no-freezing
          - training
        default: all
      dtype:
        description: Data type
        type: choice
        options:
          - all
          - amp_bf16
          - amp_fp16
          - bfloat16
          - float16
          - float32
        default: all
      models:
        description: Run all models or a subset from .github/models/{mode}/{suite}.txt
        type: choice
        options:
          - all
          - subset
        default: subset
      check_all_subset_models:
        description: In "subset" mode, keep going after errors
        type: boolean
        default: false
      only_one_model:
        description: Run only this one model
        type: string
        default: ""
      runner_label:
        description: Runner label
        type: string
        default: "b580"
      TORCH_COMPILE_DEBUG:
        description: TORCH_COMPILE_DEBUG
        type: string
        default: ""
      run_name:
        description: Custom run name
        type: string
        default: "E2E on Windows"

permissions: read-all

env:
  PYTHONIOENCODING: utf-8
  NEW_WORKSPACE: C:\gh${{ github.run_id }}
  TRITON_DISABLE_LINE_INFO: 1
  PYTHON_VERSION: "3.10"
  BENCHMARK_REPO: pytorch/benchmark

jobs:
  setup:
    name: Setup
    runs-on: linux
    outputs:
      suite: ${{ steps.set-matrix.outputs.suite }}
      mode: ${{ steps.set-matrix.outputs.mode }}
      dtype: ${{ steps.set-matrix.outputs.dtype }}
      models: ${{ steps.set-matrix.outputs.models }}
    timeout-minutes: 10
    steps:
      - name: Set matrix
        id: set-matrix
        run: |
          if [[ -z "${{ inputs.suite }}" || "${{ inputs.suite }}" == "all" ]]; then
            suite='["huggingface", "timm_models", "torchbench"]'
          else
            suite='["${{ inputs.suite }}"]'
          fi
          if [[ -z "${{ inputs.mode }}" || "${{ inputs.mode }}" == "all" ]]; then
            mode='["inference", "inference-no-freezing", "training"]'
          else
            mode='["${{ inputs.mode }}"]'
          fi
          if [[ -z "${{ inputs.dtype }}" || "${{ inputs.dtype }}" == "all" ]]; then
            dtype='["amp_bf16", "amp_fp16", "bfloat16", "float16", "float32"]'
          else
            dtype='["${{ inputs.dtype }}"]'
          fi
          if [[ -z "${{ inputs.models }}" ]]; then
            models="subset"
          else
            models="${{ inputs.models }}"
          fi
          echo "suite=$suite" >> $GITHUB_OUTPUT
          echo "mode=$mode" >> $GITHUB_OUTPUT
          echo "dtype=$dtype" >> $GITHUB_OUTPUT
          echo "models=$models" >> $GITHUB_OUTPUT

      - name: Print inputs
        run: |
          cat <<EOF
          ${{ toJSON(github.event.inputs) }}
          EOF

      - name: Print setup outputs
        run: |
          cat <<EOF
          ${{ toJSON(steps.set-matrix.outputs) }}
          EOF

  tests:
    name: Tests
    needs: setup
    runs-on:
      - windows
      - ${{ inputs.runner_label }}
    timeout-minutes: 1440 # 24h
    strategy:
      fail-fast: false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Clean up old workspaces
        shell: bash
        run: |
          rm -rf /c/gh*

      # Copy workspace to a temporary location with a shorter name.
      - name: Copy workspace
        run: |
          Copy-Item -Path ${{ github.workspace }} -Destination ${{ env.NEW_WORKSPACE }} -Recurse

      - name: Create venv
        run:
          python -m venv .venv

      # https://github.com/pytorch/data/blob/e316c5ca1ab2a4f69dd6d48e8fc9c6f8d0c7c468/README.md?plain=1#L6-L15
      - name: Install pinned torchdata
        run: |
          .venv\Scripts\activate.ps1
          pip install torchdata==0.9.0

      - name: Install PyTorch (source)
        run: |
          .venv\Scripts\activate.ps1
          Invoke-BatchFile "C:\Program Files (x86)\Intel\oneAPI\setvars.bat"
          # Required to build on Windows
          $env:CMAKE_SHARED_LINKER_FLAGS = "/FORCE:MULTIPLE"
          $env:CMAKE_MODULE_LINKER_FLAGS = "/FORCE:MULTIPLE"
          $env:CMAKE_EXE_LINKER_FLAGS = "/FORCE:MULTIPLE"
          $env:TORCH_XPU_ARCH_LIST = "bmg,dg2,arl-h,mtl-h"
          bash -c "PYTORCH_PROJ=/c/pytorch ./scripts/install-pytorch.sh --source --check-wheel"

      - name: PyTorch version
        run: |
          .venv\Scripts\activate.ps1
          Invoke-BatchFile "C:\Program Files (x86)\Intel\oneAPI\setvars.bat"
          python -c 'import torch;print(torch.__version__)' Tee-Object -Variable PYTORCH_VERSION
          echo "PYTORCH_VERSION=$PYTORCH_VERSION" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append

      - name: Clean up Triton cache
        shell: bash
        run: |
          rm -rf ~/.triton/cache

      # We need ninja >= 1.12.0 to support long names on Windows. At the moment there is no required
      # version in pypi, so instead of installing ninja with pip we use a preinstalled 1.12.1 on the
      # runner.
      - name: Setup Triton
        run: |
          .venv\Scripts\activate.ps1
          Invoke-BatchFile "C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Auxiliary\Build\vcvarsall.bat" x64
          cd ${{ env.NEW_WORKSPACE }}
          pip install -U wheel pybind11 cython cmake
          pip install -v '.[build,tests,tutorials]'

      - name: Triton version
        run: |
          .venv\Scripts\activate.ps1
          Invoke-BatchFile "C:\Program Files (x86)\Intel\oneAPI\setvars.bat"
          python -c 'import triton; print(triton.__version__)'

      - name: Identify pinned versions
        run: |
          cd c:/pytorch
          echo "BENCHMARK_COMMIT_ID=$(<.github/ci_commit_pins/torchbench.txt)" | tee -a "$GITHUB_ENV"
          echo "TORCHVISION_COMMIT_ID=$(<.github/ci_commit_pins/vision.txt)" | tee -a "$GITHUB_ENV"
          echo "TORCHAUDIO_COMMIT_ID=$(<.github/ci_commit_pins/audio.txt)" | tee -a "$GITHUB_ENV"
          echo "TRANSFORMERS_VERSION=$(<.ci/docker/ci_commit_pins/huggingface.txt)" | tee -a "$GITHUB_ENV"
          echo "TIMM_COMMIT_ID=$(<.ci/docker/ci_commit_pins/timm.txt)" | tee -a "$GITHUB_ENV"

      - name: Report environment details
        shell: bash
        run: |
          mkdir -p ${{ env.NEW_WORKSPACE }}\inductor_log
          TIMESTAMP=$(date '+%Y%m%d%H%M%S')
          echo "TIMESTAMP=$TIMESTAMP" >> "${GITHUB_ENV}"

          source ./scripts/capture-hw-details.sh --quiet

          cat <<EOF | tee ${{ env.NEW_WORKSPACE }}\inductor_log\.env
          TIMESTAMP=$TIMESTAMP
          JOB_NAME=${{ join(inputs.*, '-') }}
          GITHUB_RUN_ID=$GITHUB_RUN_ID
          GITHUB_RUN_NUMBER=$GITHUB_RUN_NUMBER
          GITHUB_RUN_ATTEMPT=$GITHUB_RUN_ATTEMPT
          E2E_MODE=${{ inputs.mode }}
          E2E_TEST_MODE=${{ inputs.test_mode }}
          E2E_SUITE=${{ inputs.suite }}
          E2E_DTYPE=${{ inputs.dtype }}
          PYTHON_VERSION=$PYTHON_VERSION
          PYTORCH_REPO=pytorch/pytorch
          PYTORCH_COMMIT_ID=$(<.github/pins/pytorch.txt)"
          PYTORCH_VERSION=$PYTORCH_VERSION
          BENCHMARK_REPO=$BENCHMARK_REPO
          BENCHMARK_COMMIT_ID=$BENCHMARK_COMMIT_ID
          TRITON_REPO=$GITHUB_REPOSITORY
          TRITON_COMMIT_ID=$GITHUB_SHA
          TORCHVISION_COMMIT_ID=$TORCHVISION_COMMIT_ID
          TORCHAUDIO_COMMIT_ID=$TORCHAUDIO_COMMIT_ID
          TRANSFORMERS_VERSION=$TRANSFORMERS_VERSION
          TIMM_COMMIT_ID=$TIMM_COMMIT_ID
          LIBIGC1_VERSION=$LIBIGC1_VERSION
          LEVEL_ZERO_VERSION=$LEVEL_ZERO_VERSION
          GPU_DEVICE=$GPU_DEVICE
          AGAMA_VERSION=$AGAMA_VERSION
          EOF

      - name: Upload test logs
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: ${{ env.NEW_WORKSPACE }}\inductor_log
          include-hidden-files: true

      - name: Clean up workspace
        if: ${{ always() }}
        run: |
          Remove-Item -LiteralPath ${{ env.NEW_WORKSPACE }} -Force -Recurse -ErrorAction Ignore

      - name: Clean up temporary files
        if: ${{ always() }}
        shell: bash
        run: |
          rm -rf rm -rf /tmp/triton-* /tmp/tmp*
