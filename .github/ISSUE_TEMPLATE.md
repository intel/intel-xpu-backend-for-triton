<!-- Thanks for contributing to the Intel® XPU Backend for Triton* project! -->

<!-- If you are submitting a feature request, please add a prefix [Feature Request] on the title. If you are submitting a bug report, please provide the following information that help us to reproduce the bug. -->

<!-- # Check Lists
Before submitting the PR, please take a look at the following check list:
1. Is this issue a known bug? Please refer to [Possible Build Bugs](https://github.com/intel/intel-xpu-backend-for-triton/wiki/Possible-Build-Bugs) and [Known Limitations](https://github.com/intel/intel-xpu-backend-for-triton/wiki/Known-Limitations) first.
2. If you build from the source, did you ping the triton version to a tested working commit? Please make sure the `openai/triton`'s commit id is the same with `triton/third_party/intel_xpu_backend/triton_hash.txt`. -->


# Issue Description
<!-- A short description for the bug. -->

# Code Example
<!-- A minimum code example for reproducing the bug. Please also attach an informational stack traces / error messages. -->

# System Info
- OS:
- PyTorch:
  <!-- - Version number / Commit id
  - How you installed (pip / build from the source) -->
- Intel Extension For Pytorch:
  <!-- - Version number / Commit id
  - How you installed (pip / build from the source) -->
- LLVM Version.
  <!-- - Submit only if you use your own LLVM. -->
- Triton Version:
  <!-- - Required if you are building from the source
  - Version number / Commit id -->
- Intel® XPU Backend for Triton*:
  <!-- - Version number / Commit id -->
