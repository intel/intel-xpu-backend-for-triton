# https://github.com/intel/intel-xpu-backend-for-triton/issues/986
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-True-False-float16-float16-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-False-False-float16-float16-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-False-True-float16-float16-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-True-True-float16-float16-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-False-False-bfloat16-bfloat16-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-False-True-bfloat16-bfloat16-None-True-None-None]
test/unit/operators/test_flash_attention.py::test_op[True-True-dtype0-2-4-512-128]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-False-True-float32-float32-None-True-None-None]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-True-True-bfloat16-bfloat16-None-True-None-None]
test/unit/operators/test_flash_attention.py::test_op[False-True-dtype0-2-4-512-128]
test/unit/operators/test_matmul.py::test_op[128-256-64-1-8-3-256-512-160-True-False-bfloat16-bfloat16-None-True-None-None]
test/unit/operators/test_flash_attention.py::test_op[True-True-dtype1-2-4-512-128]
test/unit/operators/test_flash_attention.py::test_op[True-False-dtype0-2-4-512-128]
test/unit/operators/test_flash_attention.py::test_op[False-True-dtype1-2-4-512-128]
test/unit/operators/test_flash_attention.py::test_op[True-False-dtype1-2-4-512-128]
test/unit/operators/test_flash_attention.py::test_op[False-False-dtype0-2-4-512-128]
test/unit/operators/test_flash_attention.py::test_op[False-False-dtype1-2-4-512-128]
